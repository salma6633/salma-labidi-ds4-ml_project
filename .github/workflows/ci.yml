name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  MLFLOW_TRACKING_URI: "http://mlflow:5001"
  ELASTICSEARCH_HOST: "http://localhost:9200"

jobs:
  build-test-deploy:
    runs-on: ubuntu-latest
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.5.3  # Use same version as local
        ports:
          - 9200:9200
        env:
          discovery.type: single-node
          ES_JAVA_OPTS: "-Xms512m -Xmx512m"
          xpack.security.enabled: "false"
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

      mlflow:
        image: salma6633/salma_labidi_4ds4_mlops:latest
        ports:
          - 5001:5000
        env:
          MLFLOW_TRACKING_URI: "http://mlflow:5001"
        options: >-
          --health-cmd "curl -f http://localhost:5000/ || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker for FastAPI
        run: |
          docker network create mlflow_network
          docker run -d --name fastapi-container --network mlflow_network -p 8000:8000 \
            -e MLFLOW_TRACKING_URI=http://mlflow:5001 \
            -e ELASTICSEARCH_HOST=${{ env.ELASTICSEARCH_HOST }} \
            salma6633/salma_labidi_4ds4_mlops
          
      - name: Wait for services to start
        run: sleep 15

      - name: Install dependencies
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install xgboost lifelines pytest black mypy joblib mlflow scikit-learn elasticsearch

      - name: Run tests
        run: |
          source venv/bin/activate
          pytest --maxfail=1 --disable-warnings -v

      - name: Train model and log to MLflow
        run: |
          source venv/bin/activate
          python main.py --run-all --data data_churn.csv

      - name: Upload mlruns directory as artifact
        uses: actions/upload-artifact@v4
        with:
          name: mlruns
          path: mlruns/

  build-and-push-docker:
    needs: build-test-deploy
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Log in to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build Docker image
        run: |
          docker build -t ${{ secrets.DOCKER_IMAGE }}:${{ github.sha }} .

      - name: Push Docker image
        run: |
          docker push ${{ secrets.DOCKER_IMAGE }}:${{ github.sha }}
          docker tag ${{ secrets.DOCKER_IMAGE }}:${{ github.sha }} ${{ secrets.DOCKER_IMAGE }}:latest
          docker push ${{ secrets.DOCKER_IMAGE }}:latest

  deploy:
    needs: build-and-push-docker
    runs-on: ubuntu-latest

    steps:
      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.6
        with:
          host: ${{ secrets.SERVER_IP }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            docker pull ${{ secrets.DOCKER_IMAGE }}:latest
            docker stop farmwise || true
            docker rm farmwise || true
            docker run -d --name farmwise -p 8000:8000 ${{ secrets.DOCKER_IMAGE }}:latest
